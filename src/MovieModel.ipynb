{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation Engine Tutorial\n",
    "\n",
    "This is a Notebook adaptation of a Movielens-based example on Codementor.\n",
    "\n",
    "* [Part 1](https://www.codementor.io/@jadianes/building-a-recommender-with-apache-spark-python-example-app-part1-du1083qbw)\n",
    "* [Part 2](https://www.codementor.io/@jadianes/building-a-web-service-with-apache-spark-flask-example-app-part2-du1083854)\n",
    "\n",
    "Before running this notebook, make sure that you have run `setup.sh` in the repo root to download movie recommendation data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python modules that will be used for building and training the recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:53:32.281538Z",
     "start_time": "2020-01-15T01:53:31.947327Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Pandas (used for display/debug purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:53:32.599564Z",
     "start_time": "2020-01-15T01:53:32.283922Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work out the paths to the files and directories that are relevant to the model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:53:32.607558Z",
     "start_time": "2020-01-15T01:53:32.602526Z"
    }
   },
   "outputs": [],
   "source": [
    "small_ratings_file = os.path.join('/data', 'ml-latest-small', 'ratings.csv')\n",
    "complete_ratings_file = os.path.join('/data', 'ml-latest', 'ratings.csv')\n",
    "complete_movies_file = os.path.join('/data', 'ml-latest', 'movies.csv')\n",
    "\n",
    "model_path = os.path.join('/model', 'movie_lens_als')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:53:38.204962Z",
     "start_time": "2020-01-15T01:53:32.610715Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Recommender\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4G\") \\\n",
    "    .config('spark.driver.memory', '16G') \\\n",
    "    .config('spark.driver.maxResultSize', '10G') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Train on Small Dataset\n",
    "\n",
    "This section loads a small dataset in order to train the model, i.e. tweak parameters to yield the best ALS result. The result of this step will be used in the next stage, using a larger dataset, to retrain the model for release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:53:45.095639Z",
     "start_time": "2020-01-15T01:53:38.207460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_raw_data = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .load(small_ratings_file)\n",
    "  \n",
    "small_ratings_raw_data.createOrReplaceTempView(\"ratings\")\n",
    "\n",
    "small_ratings_raw_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T21:05:03.970422Z",
     "start_time": "2020-01-14T21:05:03.958392Z"
    }
   },
   "source": [
    "Transform the raw rating dataset to something that can be used during model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:53:45.241643Z",
     "start_time": "2020-01-15T01:53:45.097482Z"
    }
   },
   "outputs": [],
   "source": [
    "small_ratings_data = spark.sql(\"select userId, movieId, rating from ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into three subsets: training, validation, and test. These will be used in training the model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:53:45.298195Z",
     "start_time": "2020-01-15T01:53:45.244236Z"
    }
   },
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6.0, 2.0, 2.0], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the ALS recommendation model by testing out three different ranks.\n",
    "\n",
    "For each rank, run an ALS model to determine which is most accurate. The best rank will be carried into building the model to use in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:54:11.067567Z",
     "start_time": "2020-01-15T01:53:45.301607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.9102254780971206\n",
      "For rank 8 the RMSE is 0.9104749136764886\n",
      "For rank 12 the RMSE is 0.9120549952009228\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    als = ALS(maxIter=iterations, regParam=regularization_parameter, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\", rank=rank)\n",
    "    model = als.fit(training_RDD)\n",
    "\n",
    "    # Evaluate the model by computing the RMSE on the test data\n",
    "    predictions = model.transform(test_RDD)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "    error = evaluator.evaluate(predictions)\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Production Model on a Larger Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:54:52.063866Z",
     "start_time": "2020-01-15T01:54:11.070221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27753444 recommendations in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_ratings_raw_data = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .load(complete_ratings_file)\n",
    "  \n",
    "complete_ratings_raw_data.createOrReplaceTempView(\"ratings\")\n",
    "\n",
    "complete_ratings_data = spark.sql(\"select userId, movieId, rating from ratings\").cache()\n",
    "\n",
    "print('There are %s recommendations in the complete dataset' % (complete_ratings_data.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameters determined during model training on the smaller recommendation dataset, retrain based on a larger volume of data to produce a version of the model that is production ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:55:14.687423Z",
     "start_time": "2020-01-15T01:54:52.066669Z"
    }
   },
   "outputs": [],
   "source": [
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7.0, 3.0], seed=0)\n",
    "\n",
    "als = ALS(maxIter=iterations, regParam=regularization_parameter, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\", rank=best_rank)\n",
    "complete_model = als.fit(training_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline and get the model ready for export. Model pipelines are used by the Arc framework, so the recommendation model needs to be compliant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:55:14.696675Z",
     "start_time": "2020-01-15T01:55:14.689622Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[complete_model])\n",
    "model = pipeline.fit(training_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the model ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:55:17.793965Z",
     "start_time": "2020-01-15T01:55:14.699714Z"
    }
   },
   "outputs": [],
   "source": [
    "model.write() \\\n",
    "  .overwrite() \\\n",
    "  .save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
