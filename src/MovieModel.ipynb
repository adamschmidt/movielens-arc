{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation Engine Tutorial\n",
    "\n",
    "This is a Notebook adaptation of a Movielens-based example on [Codementor](https://www.codementor.io/@jadianes/building-a-recommender-with-apache-spark-python-example-app-part1-du1083qbw) and the [Spark Documentation](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html) on collaborative filtering.\n",
    "\n",
    "Before running this notebook, make sure that you have run `make download` in the repo root to download movie recommendation data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Pandas (used for display/debug purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:31:29.501459Z",
     "start_time": "2020-01-16T20:31:28.553440Z"
    }
   },
   "outputs": [],
   "source": [
    "# define display options\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work out the paths to the files and directories that are relevant to the model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:31:29.512300Z",
     "start_time": "2020-01-16T20:31:29.506384Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "small_ratings_file = os.path.join('/data', 'ml-latest-small', 'ratings.csv')\n",
    "complete_ratings_file = os.path.join('/data', 'ml-latest', 'ratings.csv')\n",
    "complete_movies_file = os.path.join('/data', 'ml-latest', 'movies.csv')\n",
    "\n",
    "model_path = os.path.join('/model', 'movie_lens_als')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:31:40.259182Z",
     "start_time": "2020-01-16T20:31:29.634109Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the spark instance\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"16G\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"10G\") \\\n",
    "    .getOrCreate()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Train on Small Dataset\n",
    "\n",
    "This section loads a small dataset in order to train the model, i.e. tweak parameters to yield the best ALS result. The result of this step will be used in the next stage, using a larger dataset, to retrain the model for release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:31:49.393037Z",
     "start_time": "2020-01-16T20:31:40.262518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = spark.read.format(\"csv\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .load(small_ratings_file)\n",
    "raw_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into two subsets: training, test. These will be used in training the model below then testing against the test set to verify that no 'overfitting' has happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:31:51.940945Z",
     "start_time": "2020-01-16T20:31:49.395820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df records: 75681\n",
      "test_df records: 25155\n"
     ]
    }
   ],
   "source": [
    "# random split [75%, 25%] the enriched dataset into two datasets [train_df, test_df]\n",
    "# it is important that the test_df is reserved to test the model against unseen data to test if the model is generalised\n",
    "splits = raw_data.randomSplit([3.0, 1.0], 42)\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "train_df.cache()\n",
    "test_df.cache()\n",
    "\n",
    "print(f'train_df records: {train_df.count()}\\ntest_df records: {test_df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the ALS recommendation model by testing out three different ranks.\n",
    "\n",
    "For each rank train an ALS model to determine which is most accurate. The best rank will be carried into building the model to use in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:31:52.304210Z",
     "start_time": "2020-01-16T20:31:51.944225Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import *\n",
    "from pyspark.ml.recommendation import *\n",
    "from pyspark.ml.tuning import *\n",
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.evaluation import *\n",
    "    \n",
    "# define the model type to train - in this case an Alternating Least Squares (ALS) mode to predict a continuous variable 'prediction'\n",
    "# https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.recommendation\n",
    "# see https://spark.apache.org/docs/latest/ml-collaborative-filtering.html for implementation details\n",
    "# pay attention to cold-start-strategy which details strategy for how to deal with customers which do not have enough responses to determine their similarity to other customers\n",
    "als = ALS(\n",
    "  rank=10, \n",
    "  maxIter=10, \n",
    "  regParam=0.1, \n",
    "  numUserBlocks=10, \n",
    "  numItemBlocks=10, \n",
    "  implicitPrefs=False, \n",
    "  alpha=1.0, \n",
    "  userCol='userId', \n",
    "  itemCol='movieId', \n",
    "  seed=42, \n",
    "  ratingCol='rating', \n",
    "  nonnegative=False, \n",
    "  checkpointInterval=10, \n",
    "  intermediateStorageLevel='MEMORY_AND_DISK', \n",
    "  finalStorageLevel='MEMORY_AND_DISK', \n",
    "  coldStartStrategy='drop')    \n",
    "\n",
    "# define a sequence of stages\n",
    "# in this case we have only one stage but normally some feature engineering would happen before the model (https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.feature)\n",
    "pipeline = Pipeline(stages=[\n",
    "    als \\\n",
    "    ])\n",
    "\n",
    "# create a matrix of parameters to try whilst training\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(param=als.rank, values=[4, 8, 12]) \\\n",
    "    .build()\n",
    "\n",
    "# define the evaluation\n",
    "# this is testing prediction vs total_amount difference using the root mean square error metric\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='rating', \n",
    "    metricName='rmse')\n",
    "\n",
    "# set up the model for training\n",
    "crossValidator = CrossValidator(\n",
    "    estimator = pipeline,\n",
    "    estimatorParamMaps = paramGrid,\n",
    "    evaluator = regressionEvaluator,\n",
    "    numFolds = 3,\n",
    "    collectSubModels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:33:21.805840Z",
     "start_time": "2020-01-16T20:31:52.306810Z"
    }
   },
   "outputs": [],
   "source": [
    "# run the training on the train_df\n",
    "crossValidatorModel = crossValidator.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:34:41.318541Z",
     "start_time": "2020-01-16T20:33:21.812109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"fold\": 1, \"grid\": 1, \"rank\": 4, \"rmse\": 0.7262748350505489}\n",
      "{\"fold\": 1, \"grid\": 2, \"rank\": 8, \"rmse\": 0.6774952928110416}\n",
      "{\"fold\": 1, \"grid\": 3, \"rank\": 12, \"rmse\": 0.6548876426568273}\n",
      "{\"fold\": 2, \"grid\": 1, \"rank\": 4, \"rmse\": 0.7269762973982319}\n",
      "{\"fold\": 2, \"grid\": 2, \"rank\": 8, \"rmse\": 0.6821879249409497}\n",
      "{\"fold\": 2, \"grid\": 3, \"rank\": 12, \"rmse\": 0.6596626134414807}\n",
      "{\"fold\": 3, \"grid\": 1, \"rank\": 4, \"rmse\": 0.7296546594659135}\n",
      "{\"fold\": 3, \"grid\": 2, \"rank\": 8, \"rmse\": 0.6859068076829552}\n",
      "{\"fold\": 3, \"grid\": 3, \"rank\": 12, \"rmse\": 0.6585555992240535}\n"
     ]
    }
   ],
   "source": [
    "# to demonstrate how the training works loop through all the sub models (these are available due to collectSubModels=True) and print parameters and error rate (rmse) against the full training set. \n",
    "# running against the full training set is not entirely accurate as the CrossValidator.numFolds will seek for a more generalised model than may be exposed when evaluating against the full training set.\n",
    "# you can see that this is a brute force parameter search. This means the more .addGrid() parameters and CrossValidator.numFolds tested will result in longer training time but potentially a better model\n",
    "for fold, foldModel in enumerate(crossValidatorModel.subModels, start=1):\n",
    "    for grid, gridModel in enumerate(foldModel, start=1):\n",
    "        prediction = gridModel.transform(train_df)\n",
    "        rmse = regressionEvaluator.evaluate(prediction)\n",
    "        rank = gridModel.stages[-1].rank\n",
    "        print(f'{{\"fold\": {fold}, \"grid\": {grid}, \"rank\": {rank}, \"rmse\": {rmse}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:34:47.414963Z",
     "start_time": "2020-01-16T20:34:41.321379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rank\": 4, \"rmse\": 0.8862707366654035}\n"
     ]
    }
   ],
   "source": [
    "# test the best trained model against the reserved test set to verify no overfitting\n",
    "bestModel = crossValidatorModel.bestModel\n",
    "prediction = bestModel.transform(test_df)\n",
    "rmse = regressionEvaluator.evaluate(prediction)\n",
    "rank = bestModel.stages[-1].rank\n",
    "print(f'{{\"rank\": {rank}, \"rmse\": {rmse}}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Train on Large Dataset\n",
    "\n",
    "If the model works with the small data change the data load above and rerun from there.\n",
    "\n",
    "`\n",
    "raw_data = spark.read.format(\"csv\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .load(small_ratings_file)\n",
    "raw_data.limit(5).toPandas()\n",
    "`\n",
    "\n",
    "to:\n",
    "\n",
    "`\n",
    "raw_data = spark.read.format(\"csv\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .load(complete_ratings_file)\n",
    "raw_data.limit(5).toPandas()\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:34:47.452319Z",
     "start_time": "2020-01-16T20:34:47.424242Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-5d0b29b72933>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-5d0b29b72933>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    If you are happy with the rmse listed above export the model ready for use\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Export the model for production\n",
    "If you are happy with the rmse listed above export the model ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T20:34:47.464347Z",
     "start_time": "2020-01-16T20:32:16.692Z"
    }
   },
   "outputs": [],
   "source": [
    "bestModel.write() \\\n",
    "  .overwrite() \\\n",
    "  .save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
